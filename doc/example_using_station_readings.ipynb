{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the EWXPWSDB StationReadings Class\n",
    "\n",
    "# <span style=\"color:red\">clear all output before saving: db output contains passwords! </span>\n",
    "\n",
    "this walks through process of\n",
    "\n",
    "- creating a temporary DB\n",
    "- using the StationReading class for existing station record to\n",
    " - get station info\n",
    " - mess around with timezones\n",
    " - pull readings by date interval\n",
    " - pull hourly and daily summaries of readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants/Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "station_file = '../data/test_stations.tsv'\n",
    "station_type = 'SPECTRUM'\n",
    "station_code = 'EWXSPECTRUM01' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ewxpwsdb.db.database import create_temp_pg_engine, get_db_url, init_db, Session\n",
    "from ewxpwsdb.db.models import WeatherStation, Reading, StationType, APIResponse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create engine temp database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook_testing_nxnynxjyxn\n",
      "Station with type 'DAVIS' merged into the database\n",
      "Station with type 'LOCOMOS' merged into the database\n",
      "Station with type 'ONSET' merged into the database\n",
      "Station with type 'RAINWISE' merged into the database\n",
      "Station with type 'SPECTRUM' merged into the database\n",
      "Station with type 'ZENTRA' merged into the database\n"
     ]
    }
   ],
   "source": [
    "\n",
    "engine = create_temp_pg_engine(get_db_url(), name_prefix = 'notebook_testing')\n",
    "\n",
    "temp_db_url = engine.url\n",
    "print(temp_db_url.database)\n",
    "init_db(engine,station_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Engine, text, inspect\n",
    "\n",
    "with Session(engine) as session:\n",
    "    results = session.exec(text('show timezone;')).all()\n",
    "    print(results)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewxpwsdb.station import Station\n",
    "\n",
    "station = Station.from_station_code(station_code, engine)\n",
    "print(station.weather_station.station_type)\n",
    "print('does our station match the station type we expected?')\n",
    "station.weather_station.station_type == station_type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some data into our temp database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewxpwsdb.collector import Collector\n",
    "\n",
    "collector = Collector(station.weather_station, engine)\n",
    "print(collector.station_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up a time interval to pull data for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, UTC, timedelta\n",
    "from ewxpwsdb.time_intervals import UTCInterval\n",
    "\n",
    "today_utc = datetime.now(UTC).date()\n",
    "\n",
    "response_ids = collector.request_and_store_weather_data_utc(UTCInterval.one_day_interval())\n",
    "n_readings = len(collector.current_reading_ids)\n",
    "print(f\"store {n_readings} readings for {station_code}\")\n",
    "\n",
    "somerex = collector.request_and_store_weather_data_utc(UTCInterval.one_day_interval(d = today_utc- timedelta(days = 1)))\n",
    "n_readings = len(collector.current_reading_ids)\n",
    "print(f\"store {n_readings} readings for {station_code}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "response_ids = collector.catch_up()\n",
    "n_readings = len(collector.current_reading_ids)\n",
    "print(f\"store {n_readings} readings for {station_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StationReadings class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewxpwsdb.station import Station\n",
    "from sqlmodel import select\n",
    "\n",
    "with Session(engine) as session:            \n",
    "    stmt = select(WeatherStation).where(WeatherStation.station_code == station_code)\n",
    "    station_record:WeatherStation= session.exec(stmt).one()\n",
    "\n",
    "station_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_record.model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_station = Station.from_station_code(station_code, engine)\n",
    "test_station.weather_station\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_station.weather_station.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = test_station.weatherstation_plus_sql()\n",
    "for line in sql.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_station.station_with_detail(engine).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging WeatherStationDetail class\n",
    "\n",
    "this is a class that is Pydantic Base model with class methods to create from station code and engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewxpwsdb.station import WeatherStationDetail\n",
    "wsd:WeatherStationDetail = WeatherStationDetail.with_detail(station_code = station_code, engine = engine)\n",
    "print(wsd.model_dump_json(indent = 4))\n",
    "wsd.first_reading_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert wsd.first_reading_datetime is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we use supported vars to check things?  that field looks it's stored kinda wonky in data model, but it's JSON!\n",
    "\n",
    "var_of_interest = 'lws'\n",
    "import json\n",
    "if var_of_interest in json.loads(wsd.supported_variables):\n",
    "    print('var is in there -- we can do the thing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewxpwsdb.station_readings import StationReadings\n",
    "\n",
    "\n",
    "station_readings = StationReadings(station = test_station.weather_station, engine = engine)\n",
    "\n",
    "print(station_readings.station.station_code)\n",
    "print(station_readings.station.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readings = station_readings.recent_readings()\n",
    "print(readings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a date interval to use to pull data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from zoneinfo import ZoneInfo\n",
    "from datetime import date\n",
    "from ewxpwsdb.time_intervals import DateInterval\n",
    "\n",
    "dates = DateInterval(start = date(2024, 6, 8), end = date(2024, 6, 12), local_timezone = ZoneInfo(\"America/Detroit\") )\n",
    "utc_interval = dates.to_utc_datetime_interval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get more readings with collector, pull them with station_readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector.request_and_store_weather_data_utc(utc_interval)\n",
    "print(f\"stored {len(collector.current_reading_ids)} readings \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing complex SQL to pull hourly summary of readings by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewxpwsdb.db.summary_models import HourlySummary\n",
    "\n",
    "start_date=dates.start\n",
    "end_date=dates.end\n",
    "sql_str = HourlySummary.sql_str(station_id= station.weather_station.id, local_start_date=dates.start, local_end_date=dates.end, station_timezone=station.weather_station.timezone)\n",
    "for line in sql_str.split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day = DateInterval(start = date(2024, 6, 9), end = date(2024, 6, 10), local_timezone = ZoneInfo(\"America/Detroit\") )\n",
    "\n",
    "records = station_readings.hourly_summary(local_start_date = one_day.start, local_end_date=one_day.end )\n",
    "print(len(records))\n",
    "if (len(records) > 0 ):\n",
    "    print(records[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "\n",
    "remove test database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ewxpwsdb.db.database import drop_pg_db, list_pg_databases\n",
    "from sqlalchemy.orm import close_all_sessions\n",
    "\n",
    "# if collector:\n",
    "#     collector._session.close()\n",
    "#     collector._engine.dispose()\n",
    "\n",
    "close_all_sessions()\n",
    "\n",
    "print(f\"attempting to drop db {engine.url.database}\")\n",
    "result = drop_pg_db(engine)\n",
    "print(result)\n",
    "engine.dispose()\n",
    "list_pg_databases(host='localhost')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ewxpwsdb-Ylvp0c_2-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
