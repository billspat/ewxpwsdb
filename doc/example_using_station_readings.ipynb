{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the EWXPWSDB StationReadings Class\n",
    "\n",
    "# <span style=\"color:red\">clear all output before saving: db output contains passwords! </span>\n",
    "\n",
    "this walks through process of\n",
    "\n",
    "- creating a temporary DB\n",
    "- using the StationReading class for existing station record to\n",
    " - get station info\n",
    " - mess around with timezones\n",
    " - pull readings by date interval\n",
    " - pull hourly and daily summaries of readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants/Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "station_file = '../data/test_stations.tsv'\n",
    "station_type = 'SPECTRUM'\n",
    "station_code = 'EWXSPECTRUM01' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ewxpwsdb.db.database import create_temp_pg_engine, get_db_url, init_db, Session\n",
    "from ewxpwsdb.db.models import WeatherStation, Reading, StationType, APIResponse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create engine temp database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook_testing_mh9lz7da9n\n",
      "Station with type 'DAVIS' merged into the database\n",
      "Station with type 'LOCOMOS' merged into the database\n",
      "Station with type 'ONSET' merged into the database\n",
      "Station with type 'RAINWISE' merged into the database\n",
      "Station with type 'SPECTRUM' merged into the database\n",
      "Station with type 'ZENTRA' merged into the database\n"
     ]
    }
   ],
   "source": [
    "\n",
    "engine = create_temp_pg_engine(get_db_url(), name_prefix = 'notebook_testing')\n",
    "\n",
    "temp_db_url = engine.url\n",
    "print(temp_db_url.database)\n",
    "init_db(engine,station_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('UTC',)]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import Engine, text, inspect\n",
    "\n",
    "with Session(engine) as session:\n",
    "    results = session.exec(text('show timezone;')).all()\n",
    "    print(results)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECTRUM\n",
      "does our station match the station type we expected?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ewxpwsdb.station import Station\n",
    "\n",
    "station = Station.from_station_code(station_code, engine)\n",
    "print(station.weather_station.station_type)\n",
    "print('does our station match the station type we expected?')\n",
    "station.weather_station.station_type == station_type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some data into our temp database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWXSPECTRUM01\n"
     ]
    }
   ],
   "source": [
    "from ewxpwsdb.collector import Collector\n",
    "\n",
    "collector = Collector(station.weather_station, engine)\n",
    "print(collector.station_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up a time interval to pull data for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store 48 readings for EWXSPECTRUM01\n",
      "store 287 readings for EWXSPECTRUM01\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, UTC, timedelta\n",
    "from ewxpwsdb.time_intervals import UTCInterval\n",
    "\n",
    "today_utc = datetime.now(UTC).date()\n",
    "\n",
    "response_ids = collector.request_and_store_weather_data_utc(UTCInterval.one_day_interval())\n",
    "n_readings = len(collector.current_reading_ids)\n",
    "print(f\"store {n_readings} readings for {station_code}\")\n",
    "\n",
    "somerex = collector.request_and_store_weather_data_utc(UTCInterval.one_day_interval(d = today_utc- timedelta(days = 1)))\n",
    "n_readings = len(collector.current_reading_ids)\n",
    "print(f\"store {n_readings} readings for {station_code}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "response_ids = collector.catch_up()\n",
    "n_readings = len(collector.current_reading_ids)\n",
    "print(f\"store {n_readings} readings for {station_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StationReadings class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeatherStation(station_code='EWXSPECTRUM01', id=3, lat=42.70736, location_description='EWX Field Office', api_config='{\"sn\":\"50400123\",\"apikey\":\"11a5c3a939856b08677b7a072f8e6865\"}', install_date=datetime.date(2023, 5, 1), timezone='US/Eastern', station_type='SPECTRUM', ewx_user_id='0', lon=84.46512, background_place='HTC')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ewxpwsdb.station import Station\n",
    "from sqlmodel import select\n",
    "\n",
    "with Session(engine) as session:            \n",
    "    stmt = select(WeatherStation).where(WeatherStation.station_code == station_code)\n",
    "    station_record:WeatherStation= session.exec(stmt).one()\n",
    "\n",
    "station_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"station_code\":\"EWXSPECTRUM01\",\"id\":3,\"lat\":42.70736,\"location_description\":\"EWX Field Office\",\"api_config\":\"**api login hidden**\",\"install_date\":\"2023-05-01\",\"timezone\":\"US/Eastern\",\"station_type\":\"SPECTRUM\",\"ewx_user_id\":\"0\",\"lon\":84.46512,\"background_place\":\"HTC\"}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_record.model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeatherStation(station_code='EWXSPECTRUM01', id=3, lat=42.70736, location_description='EWX Field Office', api_config='{\"sn\":\"50400123\",\"apikey\":\"11a5c3a939856b08677b7a072f8e6865\"}', install_date=datetime.date(2023, 5, 1), timezone='US/Eastern', station_type='SPECTRUM', ewx_user_id='0', lon=84.46512, background_place='HTC')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_station = Station.from_station_code(station_code, engine)\n",
    "test_station.weather_station\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_station.weather_station.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select \n",
      "            weatherstation.*,\n",
      "            stationtype.sampling_interval,\n",
      "            stationtype.supported_variables,\n",
      "            min(reading.data_datetime at time zone weatherstation.timezone) first_reading_datetime, \n",
      "            min(reading.data_datetime) as first_reading_datetime_utc,\n",
      "            max(reading.data_datetime at time zone weatherstation.timezone) as latest_reading_datetime, \n",
      "            max(reading.data_datetime) as latest_reading_datetime_utc,\n",
      "            60/stationtype.sampling_interval::int as expected_readings_hour,\n",
      "            (24*60)/stationtype.sampling_interval::int as expected_readings_day\n",
      "        from \n",
      "            weatherstation inner join stationtype on weatherstation.station_type = stationtype.station_type\n",
      "            inner join reading on weatherstation.id = reading.weatherstation_id \n",
      "        where \n",
      "            weatherstation.id = 3\n",
      "        group by \n",
      "            weatherstation.id, stationtype.sampling_interval, stationtype.supported_variables\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "sql = test_station.weatherstation_plus_sql()\n",
    "for line in sql.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 3,\n",
       " 'station_code': 'EWXSPECTRUM01',\n",
       " 'station_type': 'SPECTRUM',\n",
       " 'install_date': datetime.date(2023, 5, 1),\n",
       " 'timezone': 'US/Eastern',\n",
       " 'ewx_user_id': '0',\n",
       " 'lat': 42.70736,\n",
       " 'lon': 84.46512,\n",
       " 'location_description': 'EWX Field Office',\n",
       " 'background_place': 'HTC',\n",
       " 'api_config': SecretStr('**********'),\n",
       " 'sampling_interval': 5,\n",
       " 'expected_readings_day': 288,\n",
       " 'expected_readings_hour': 12,\n",
       " 'first_reading_datetime': datetime.datetime(2024, 6, 24, 20, 0),\n",
       " 'first_reading_datetime_utc': datetime.datetime(2024, 6, 25, 0, 0, tzinfo=datetime.timezone.utc),\n",
       " 'latest_reading_datetime': datetime.datetime(2024, 6, 25, 23, 55),\n",
       " 'latest_reading_datetime_utc': datetime.datetime(2024, 6, 26, 3, 55, tzinfo=datetime.timezone.utc),\n",
       " 'supported_variables': '[\"atmp\", \"lws\", \"pcpn\", \"relh\", \"srad\", \"wspd\", \"wdir\", \"wspd_max\"]'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_station.station_with_detail(engine).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging WeatherStationDetail class\n",
    "\n",
    "this is a class that is Pydantic Base model with class methods to create from station code and engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": 3,\n",
      "    \"station_code\": \"EWXSPECTRUM01\",\n",
      "    \"station_type\": \"SPECTRUM\",\n",
      "    \"install_date\": \"2023-05-01\",\n",
      "    \"timezone\": \"US/Eastern\",\n",
      "    \"ewx_user_id\": \"0\",\n",
      "    \"lat\": 42.70736,\n",
      "    \"lon\": 84.46512,\n",
      "    \"location_description\": \"EWX Field Office\",\n",
      "    \"background_place\": \"HTC\",\n",
      "    \"api_config\": \"**********\",\n",
      "    \"sampling_interval\": 5,\n",
      "    \"expected_readings_day\": 288,\n",
      "    \"expected_readings_hour\": 12,\n",
      "    \"first_reading_datetime\": \"2024-06-24T20:00:00\",\n",
      "    \"first_reading_datetime_utc\": \"2024-06-25T00:00:00Z\",\n",
      "    \"latest_reading_datetime\": \"2024-06-25T23:55:00\",\n",
      "    \"latest_reading_datetime_utc\": \"2024-06-26T03:55:00Z\",\n",
      "    \"supported_variables\": \"[\\\"atmp\\\", \\\"lws\\\", \\\"pcpn\\\", \\\"relh\\\", \\\"srad\\\", \\\"wspd\\\", \\\"wdir\\\", \\\"wspd_max\\\"]\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 6, 24, 20, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ewxpwsdb.station import WeatherStationDetail\n",
    "wsd:WeatherStationDetail = WeatherStationDetail.with_detail(station_code = station_code, engine = engine)\n",
    "print(wsd.model_dump_json(indent = 4))\n",
    "wsd.first_reading_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert wsd.first_reading_datetime is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var is in there -- we can do the thing!\n"
     ]
    }
   ],
   "source": [
    "# can we use supported vars to check things?  that field looks it's stored kinda wonky in data model, but it's JSON!\n",
    "\n",
    "var_of_interest = 'lws'\n",
    "import json\n",
    "if var_of_interest in json.loads(wsd.supported_variables):\n",
    "    print('var is in there -- we can do the thing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewxpwsdb.station_readings import StationReadings\n",
    "\n",
    "\n",
    "station_readings = StationReadings(station = test_station.weather_station, engine = engine)\n",
    "\n",
    "print(station_readings.station.station_code)\n",
    "print(station_readings.station.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readings = station_readings.recent_readings()\n",
    "print(readings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a date interval to use to pull data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from zoneinfo import ZoneInfo\n",
    "from datetime import date\n",
    "from ewxpwsdb.time_intervals import DateInterval\n",
    "\n",
    "dates = DateInterval(start = date(2024, 6, 8), end = date(2024, 6, 12), local_timezone = ZoneInfo(\"America/Detroit\") )\n",
    "utc_interval = dates.to_utc_datetime_interval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get more readings with collector, pull them with station_readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector.request_and_store_weather_data_utc(utc_interval)\n",
    "print(f\"stored {len(collector.current_reading_ids)} readings \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing complex SQL to pull hourly summary of readings by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewxpwsdb.db.summary_models import HourlySummary\n",
    "\n",
    "start_date=dates.start\n",
    "end_date=dates.end\n",
    "sql_str = HourlySummary.sql_str(station_id= station.weather_station.id, local_start_date=dates.start, local_end_date=dates.end, station_timezone=station.weather_station.timezone)\n",
    "for line in sql_str.split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day = DateInterval(start = date(2024, 6, 9), end = date(2024, 6, 10), local_timezone = ZoneInfo(\"America/Detroit\") )\n",
    "\n",
    "records = station_readings.hourly_summary(local_start_date = one_day.start, local_end_date=one_day.end )\n",
    "print(len(records))\n",
    "if (len(records) > 0 ):\n",
    "    print(records[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "\n",
    "remove test database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ewxpwsdb.db.database import drop_pg_db, list_pg_databases\n",
    "from sqlalchemy.orm import close_all_sessions\n",
    "\n",
    "# if collector:\n",
    "#     collector._session.close()\n",
    "#     collector._engine.dispose()\n",
    "\n",
    "close_all_sessions()\n",
    "\n",
    "print(f\"attempting to drop db {engine.url.database}\")\n",
    "result = drop_pg_db(engine)\n",
    "print(result)\n",
    "engine.dispose()\n",
    "list_pg_databases(host='localhost')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ewxpwsdb-Ylvp0c_2-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
